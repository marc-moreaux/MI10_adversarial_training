\chapter{Conclusion}
\label{sec:conclusion}
	Time has almost come to conclude on the work that have been done. But, before that, lets summarize what we did. At the very beginning of this thesis, we mentioned our motivations on writing this thesis. We wanted to work on adversarial-training to understand the underlining advantage of it over a more basic approach. We wanted to expose the linearity of the basic approach and how adversarial-learning generalizes. Also we wanted to figure out if this technique could work on another dataset.

	After all the experiment we've been through, we can most probably conclude that basic-learning (A) on shallow-neural-networks \textbf{doesn't generalize} the data distribution it is trained on and is therefore too linear. We came to this conclusion by predicting on a this model an adversarial test-sets and observing how quickly it could be misled. Also, comparing another model (C) trained on random modifications, to our model A confirmed this observation, that a model trained to generalize a data distribution was less linear. This last point might sound obvious but is key as A could have been as good as C if it had generalized. Comparing the amount of neurons on the adversarial model (B) lead us to believe that B learns more functions than A does and might generalize with these new functions. Finally, comparing this technique on other datasets let us realize that this technique was specific to a certain type of inputs features and that non linear features most probably aren't concerned with adversarial-learning.

	We didn't exactly found what adversarial-learning was specifically doing. My hypothesis would be that it better separate the classes by learning what makes the class different from the others. Visualizing the weights and comparing A and B's weights would have helped us on validating this hypothesis but we can't visualize patterns with this type of networks.

	\vskip 1cm
	This last observation leads us to a desired \textbf{future work}: We would like to confirm the hypothesis stated right above by training another type of network where we can visualize the class patterns and where the adversarial-learning is also better than the basic one.