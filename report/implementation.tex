
\section{Implementation}

	In this section we present the software we chose to implement our solution. The elected software comes from the Lisa-lab\footnote{url{https://github.com/lisa-lab}} in Montreal and is called Pylearn2. The Lisa lab is specialized in neural-network and more specifically, deep learning. Yan Goodfellow, one of the writers of the paper\cite{goodfellow2014explaining}, was part of this institution, he is one of the main contributor of Pylearn2 and write most of his paper with this tool. His implementation of Adversarial-learning was made with this tool. In the following section, we are going to present the software's needs we had with respect to this thesis and on the next one we'll explore the way Pylearn2 works.

	\subsection{software needs}
		At the very beginning of this thesis we searched for a good software with respect to many needs.
		Of course, as we are doing neural-nets, our first need was to have a software able to implement a neural-network. Then there was some other needs. The learning curve for this software had to be steep enough so that we could implement our solution in some reasonable time. After this, the software had to flexible towards our needs of adversarial-learning. Indeed, the cost of our shallow-feed-forward network had to be modified in order to accept adversarial-learning. Also, as we have large databases like the Cifar-10 (composed by $60k$ sample of $3k$ values each), the software's algorithms had to perform fast operations. To show the importance of this criterion, with the software we finally choose, it took us more that 36 hours to compute the adversarial model of Cifar-10.

		In neural networks there was 4 main softwares answering partially our needs.
		\begin{itemize}
			\item Torch: "Torch is a scientific computing framework with wide support for machine learning algorithms". Their framework is very easy to use. In one hour you can build a neural-network classifying MNIST. Now, the implementation of new functions is complicated. Implementing a new cost function is hard, it's for this reason that we didn't chose this soft.
			\item Lush: "Lush is an programming language designed for researchers, experimenters, and engineers interested in large-scale numerical and graphic applications". Even though the description seems appealing, the software isn't maintained and doesn't embed modern gradient descent algorithms. 
			\item Pylearn2: "Pylearn2 is a machine learning library". It was designed for deep-learning, is written in python and can differentiate function. Because it also fulfills all the software needs, this alternative was chosen.
			\item Matlab: The very famous Matlab could have been used for our project. Now the libraries provided weren't as specific as the other softwares.
			\item R: "R is a language and environment for statistical computing and graphics". This language integrates deep-learning algorithms but was not mentioned as a reference in the deep leaning domain.
		\end{itemize}


		Advantage and drawbacks of Pylearn2:

		On the one hand, Pylearn2 is written in Python: a very common and easy to understand language. That makes a big advantage to Pylearn2 toward a soft written in C or Lua. On the other hand, Pylearn2 uses a file format called "Yaml" to build and train the networks. These files are made so that you can easily call classes with many parameters. Though it's practical, it's hard to understand this approach if you've never seen something similar before.
		Pylearn2 is being under development which makes it a software up to date. Now, this advantage is also a drawback as the python documentation isn't as furnished as one could expect nor are the error messages. It was often needed during the implementation to browse specific forums and investigate on which could be a good solution for us. Thought the python documentation lacks of details, a blog is maintained by the Lisa-lab to introduce to their tools.
		At this point, Pylearn2 is far from being the easiest tool to use in order to build and trained a neural-network, but what really came in the balance to support it use is a useful library on which it relies: Theano. Theano, also developed in the Lisa lab. It's "a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently". This library also include automatic differentiation, so that you can create a new cost function without having to differentiate it by hand.

		I'll finish these motivations mentioning that Pylearn2 is hard to get into. One need to spend some time on the code, on the blog and on the forums to builds its own models but, at the end, Pylearn2 is very flexible and offer a useful tool of differentiation to rapidly test new cost functions.


	\subsection{Pylearn2}
		Lets now present the tool. Pylearn2 is a python library. It mainly relies on Numpy, for matrix manipulation and on Theano, for optimized operations on matrices. There is three main files on Pylearn2: the model, the cost and the routine files. Following comes the description of them. You may watch before \fref{fig:pylearn2} for a graphical representation of the system.
		\begin{itemize}
		  	\item The model: The model is represented by a class in Pylearn2. It has to follow rhe sucture of an abstract class (\textit{pylearn2.models.model.Model}) in order to work with the system. In supervised learning (what we are doing), this model will be called by the cost to compute it. The model, in our case, is a shallow-feed-forward-neural-network. An flexible implementation of this model is already available on the Pylearn2 library.
		  	\item The cost: In Pylearn2 philosophy, one should be able to modify easily the cost to test it. This is the strength of Pylearn2, where you would give the cost and the library will differentiate it. This ease implies some difficulties as the user has to input a cost in a 'Theano-symbolic' format. In the system, this cost is also represented by an abstract class (\textit{pylearn2.costs.cost.Cost}) where the user must implement the 'expr' function which outputs the 'Theano-symbolic' function.
		  	\item The routine: Finally, when one desire to build a model with a specific cost and a specific learning algorithm, one will create a 'yaml' file. This file is only composed by classes calls. For the training, the library expects first the \textit{Train} class containing both the \textit{Model} one and the \textit{Learning algorithm} class which itself contains the \textit{Cost} class. With these classes and the dataset given as parameters of them, Pylearn2 will initiate a learning process.
	  	\end{itemize}
			 
		\begin{figure}[H]
			\centering
			\def\layersep{8em}	
			\begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=\layersep]
			    \tikzstyle{annot} = [text width=6em, text centered]
			    \tikzstyle{doc}  = [draw,thick,anchor=west,color=black,shape=document,minimum width=4em,minimum height=5em,inner sep=2ex]
			    \tikzstyle{doc1} = [draw,thick,anchor=west,color=black,shape=document,minimum width=4em,minimum height=2em,inner sep=1ex]
			    \tikzstyle{save} = [draw,thick,anchor=west,color=black,shape=rectangle,minimum width=4em,minimum height=5em,inner sep=1ex]
			    \tikzstyle{db}   = [draw,thick,anchor=west,color=black,cylinder,minimum width=4em,minimum height=5em,inner sep=2ex, rotate=90]
			    \tikzstyle{rect} = [draw,thick,anchor=west,color=black,shape=rectangle,minimum width=4em,minimum height=5em,]

			   	
			   	\node[doc]  (ROUT) at (2,0)   {.yaml}; \node[annot,above of=ROUT, node distance=3em] {routine};
			   	\node[doc1] (COST) at (0,-.8) {.py};   \node[annot,above of=COST, node distance=1.5em] {cost};
			   	\node[doc1] (MODL) at (0,.5)  {.py};   \node[annot,above of=MODL, node distance=1.5em] {model};
			   	\node[save] (SAVE) at (5,0)   {.pkl};  \node[annot,above of=SAVE, node distance=3em] {saved model};


			   	\node[rect, minimum width=11em, minimum height=4.2em] (PYLE)  at (0,-2.5) {pylearn2};
			   	\node[rect, minimum width=5em,  minimum height=1em]   (THEA)    at (2.1,-3) {Theano};
			   	\node[rect, minimum width=11em, minimum height=4em]   (PYTH)    at (0,-4) {Python};
			   	
			   	\node[db]   (DB)    at (5.7,-4.8) {data base};


			   	\path (ROUT) edge (PYLE);
			   	\path (ROUT) edge (COST);
			   	\path (ROUT) edge (MODL);
			   	\path (ROUT) edge (DB);
			   	\path (ROUT) edge[double distance = 1.5pt] (SAVE);
			   	\path (COST)  edge (PYLE);
			   	\path (COST)  edge (MODL);
			\end{tikzpicture}
			\caption{Graphical representation of Pylearn2's routine}
			\label{fig:pylearn2}
		\end{figure}

	\subsection{Our implementation}
		We decided to re-implement the adversarial-learning for two reasons. The first one was to get more insights on the way Pylearn2 works and the second reason was that there were no available code doing adversarial-learning. At the end, the code produced is very easy to understand. None the less, this bit of code doesn't reflect the difficulties of writing it, as there is a huge lack of documentation and proper error logs on Pylearn2.

		\vskip 1em
		We won't present here the \textbf{model} for two reasons. At first we used an implementation that provided in the library, and, secondly, because the code is hundreds of lines. How-ever, the code beneath the model does what we expected it to do. It creates a layers of Regression Logistic Units and ends up with a softmax layer.

		Then comes the implementation of the \textbf{cost}. On the constructor we define a learning epsilon value that will be able to modify when calling the routine. Then, the 'expr' function computes the adversarial-cost in a Theano-symbolic way.

		\lstset{language=Python}
		\begin{lstlisting}[basicstyle=\small,frame=single]
class AdversarialCost(DefaultDataSpecsMixin, Cost):
    # The default Cost to use with an MLP.
    supervised = True

    def __init__(self, learning_eps):
        self.learning_eps = learning_eps
        

    def expr(self, model, data, **kwargs):
    	# check input space
        space, sources = self.get_data_specs(model)
        space.validate(data)
        
        # Compute adversarial cost
        X, y = data
        alpha = .5
        adv_X = X + self.learning_eps 
        	* T.sgn(T.grad(model.cost_from_X(data),X))
        adv_data = (adv_X, y)

        return alpha*model.cost_from_X(data) 
        	+ (1-alpha)*model.cost_from_X(adv_data)

    @wraps(Cost.is_stochastic)
    def is_stochastic(self):
        return False
.
		\end{lstlisting}

		Finally, the \textbf{routine} file (the .yaml one) covers all the function calls. At first you call Pylearn2's \textit{Training} class. Then you define the model you want to train, here a ReLU shallow-neural-net. On the example below, the network is composed by 784 input units (for the MNIST database), 1200 ReLU hidden units on a single layer and a softmax output layer composed by 10 classes. Here, each of the classes will refer to a digit class. After the model comes the \textit{learning algorithm} class. We elected the Standard Gradient Descent (SDG) with some improvements: we use a batch version of it so the results comes quicker and add a momentum to the learning rate so that learning takes into consideration its previous moves when following the gradient. Still in the SDG, we elected common early-stopping stopping technique based on a validation set: we train on a testing set and, when ever the validation set show that training is over-fitting we stop the training. Furthermore, we use a rollback so that we don't consider over-fitting to early, in other words, the learning wont stop as soon as the validation states it performs worst than the train set, but we wait a hundred iteration before claiming the over-fitting (still based on the train set outperforming the validation set = over-fitting). Finally comes the cost related to the learning algorithm. Here we use the one we've shown previously: the adversarial cost. In this class comes a learning epsilon, it is the one of equation \ref{eq:sample_twist}. When given $0$, it's an usual cross-entropy learning and when given a value between $]0,1[$ it's an adversarial learning. 

		\lstset{language=Python}
		\begin{lstlisting}[basicstyle=\small,frame=single]
!obj:pylearn2.train.Train {
  dataset: &train !obj:pylearn2.datasets.
        dense_design_matrix.DenseDesignMatrix {
    X: !pkl: '/home/marc/data/mnist_train_X.pkl',
    y: !pkl: '/home/marc/data/mnist_train_y.pkl',
    y_labels: 10,
  },
  model: !obj:pylearn2.models.mlp.MLP {
    layers:[!obj:pylearn2.models.mlp.RectifiedLinear{
         layer_name: 'h0',
         dim: 1200,
         sparse_init: 15
       }, !obj:pylearn2.models.mlp.Softmax {
         layer_name: 'y',
         n_classes: 10,
         irange: 0.
       }
    ],
    nvis: 784,
  },
  algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
    batch_size: 200,
    learning_rate: .01,
    learning_rule: !obj:pylearn2.training_algorithms
        .learning_rule.Momentum {
      init_momentum: .5 },
    monitoring_dataset: {
      'train' : *train,
      'valid' : !obj:pylearn2.(...).DenseDesignMatrix {
        X: !pkl: '/home/marc/data/mnist_valid_X.pkl',
        y: !pkl: '/home/marc/data/mnist_valid_y.pkl',
        y_labels: 10,
      },
      'test' : !obj:pylearn2.(...).DenseDesignMatrix {
        X: !pkl: '/home/marc/data/mnist_test_X.pkl',
        y: !pkl: '/home/marc/data/mnist_test_y.pkl',
        y_labels: 10,
      }, },
    termination_criterion:!obj:pylearn2.
    	termination_criteria.And { criteria: [
        !obj:pylearn2.termination_criteria.MonitorBased {
            channel_name: "valid_y_misclass",
            prop_decrease: 0.,
            N: 100
        },
        !obj:pylearn2.termination_criteria.EpochCounter {
            max_epochs: 1500
        }
      ]
    },
    cost: !obj:costAdv.AdversarialCost {
      learning_eps: %(learning_eps)f }
  },
  extensions: [
    !obj:pylearn2.(...).MonitorBasedSaveBest {
       channel_name: 'valid_y_misclass',
       save_path: "%(path)s/mlp_1_%(learning_eps)s.pkl",
    }, !obj:pylearn2.(...).MomentumAdjustor {
      start: 1,
      saturate: 10,
      final_momentum: .99
    }
  ]
}
		\end{lstlisting}

		As a note, one may wonder why is the cost inside the learning algorithm. The reason is that some neural-networks can be unsupervised, meaning that their cost doesn't depends on their inputs. As a result, the learning algorithm just doesn't ask for a cost. 

